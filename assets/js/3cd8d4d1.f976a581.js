"use strict";(self.webpackChunkpy_tfhe_oss_doc=self.webpackChunkpy_tfhe_oss_doc||[]).push([[1016],{8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>c});var r=i(6540);const s={},t=r.createContext(s);function l(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(t.Provider,{value:n},e.children)}},8658:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>u,frontMatter:()=>l,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"submodules/pytfhe-frontend/runner","title":"Boolean TFHE Program Runner","description":"The runner module provides the core execution engines for running FHE circuits. It supports multiple execution backends including CPU (serial and Ray distributed), GPU (CUDA), and various FHE libraries (pyTFHE, cuFHE). The module handles scheduling, batching, and parallel execution of FHE operations.","source":"@site/docs/submodules/pytfhe-frontend/runner.md","sourceDirName":"submodules/pytfhe-frontend","slug":"/submodules/pytfhe-frontend/runner","permalink":"/pytfhe/docs/submodules/pytfhe-frontend/runner","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/submodules/pytfhe-frontend/runner.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"TFHE Assembly (TASM) Tools","permalink":"/pytfhe/docs/submodules/pytfhe-frontend/asm-tools"},"next":{"title":"Benchmark Submodule","permalink":"/pytfhe/docs/submodules/pytfhe-frontend/benchmark"}}');var s=i(4848),t=i(8453);const l={sidebar_position:4},c="Boolean TFHE Program Runner",o={},d=[{value:"Core Components",id:"core-components",level:2},{value:"Main Execution Engines",id:"main-execution-engines",level:3},{value:"CPU Execution (<code>main.py</code>)",id:"cpu-execution-mainpy",level:4},{value:"GPU Execution (<code>main_gpu.py</code>)",id:"gpu-execution-main_gpupy",level:4},{value:"Ray-Based Distributed Computing",id:"ray-based-distributed-computing",level:3},{value:"Worker Pool (<code>ray_worker.py</code>)",id:"worker-pool-ray_workerpy",level:4},{value:"Circuit Execution Runners",id:"circuit-execution-runners",level:3},{value:"LUT-Based Runner (<code>tnfs_lut2_runner.py</code>)",id:"lut-based-runner-tnfs_lut2_runnerpy",level:4},{value:"TFHE Runners (<code>tfhe_*.py</code>)",id:"tfhe-runners-tfhe_py",level:4},{value:"Alternative FHE Backends",id:"alternative-fhe-backends",level:3},{value:"cuFHE Integration (<code>cuFHE_runner.py</code>, <code>cufhe_benchmark_driver.py</code>)",id:"cufhe-integration-cufhe_runnerpy-cufhe_benchmark_driverpy",level:4},{value:"LibFHE Support (<code>libfhe.py</code>)",id:"libfhe-support-libfhepy",level:4},{value:"Benchmarking and Profiling",id:"benchmarking-and-profiling",level:3},{value:"GPU Benchmarking (<code>gpu_benchmark_driver.py</code>)",id:"gpu-benchmarking-gpu_benchmark_driverpy",level:4},{value:"Sweep Testing (<code>sweep.py</code>)",id:"sweep-testing-sweeppy",level:4},{value:"Execution Modes",id:"execution-modes",level:2},{value:"Serial Execution",id:"serial-execution",level:3},{value:"Ray Distributed Execution",id:"ray-distributed-execution",level:3},{value:"GPU Execution",id:"gpu-execution",level:3},{value:"Circuit Format Support",id:"circuit-format-support",level:2},{value:"LUT Binary Format",id:"lut-binary-format",level:3},{value:"TNFS Binary Format",id:"tnfs-binary-format",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Batching Strategies",id:"batching-strategies",level:3},{value:"Memory Management",id:"memory-management",level:3},{value:"Scheduling Integration",id:"scheduling-integration",level:3},{value:"Usage Examples",id:"usage-examples",level:2},{value:"Basic Circuit Execution",id:"basic-circuit-execution",level:3},{value:"GPU Execution",id:"gpu-execution-1",level:3},{value:"Ray Cluster Setup",id:"ray-cluster-setup",level:3}];function a(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"boolean-tfhe-program-runner",children:"Boolean TFHE Program Runner"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"runner"})," module provides the core execution engines for running FHE circuits. It supports multiple execution backends including CPU (serial and Ray distributed), GPU (CUDA), and various FHE libraries (pyTFHE, cuFHE). The module handles scheduling, batching, and parallel execution of FHE operations."]}),"\n",(0,s.jsx)(n.h2,{id:"core-components",children:"Core Components"}),"\n",(0,s.jsx)(n.h3,{id:"main-execution-engines",children:"Main Execution Engines"}),"\n",(0,s.jsxs)(n.h4,{id:"cpu-execution-mainpy",children:["CPU Execution (",(0,s.jsx)(n.code,{children:"main.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Main entry point for CPU-based FHE circuit execution with Ray distributed computing."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Features:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Command-line interface for circuit execution"}),"\n",(0,s.jsx)(n.li,{children:"Ray cluster integration for distributed computing"}),"\n",(0,s.jsx)(n.li,{children:"LUT-based circuit execution"}),"\n",(0,s.jsx)(n.li,{children:"Support for both serial and parallel modes"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Usage:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python -m pyTNFS.runner.main -i circuit.lut -c 8 --ray ray://cluster:10001\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Workflow:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Load and decompress LUT binary circuit"}),"\n",(0,s.jsx)(n.li,{children:"Initialize FHE parameters and keys"}),"\n",(0,s.jsx)(n.li,{children:"Create input ciphertexts"}),"\n",(0,s.jsx)(n.li,{children:"Schedule operations using greedy scheduler"}),"\n",(0,s.jsx)(n.li,{children:"Execute using Ray workers or serial execution"}),"\n",(0,s.jsx)(n.li,{children:"Collect and decrypt outputs"}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"gpu-execution-main_gpupy",children:["GPU Execution (",(0,s.jsx)(n.code,{children:"main_gpu.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"CUDA GPU-accelerated execution using pyTFHEGPU backend."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Features:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"CUDA acceleration for FHE operations"}),"\n",(0,s.jsx)(n.li,{children:"Batch processing with configurable batch sizes"}),"\n",(0,s.jsx)(n.li,{children:"Megabatch support for large circuits"}),"\n",(0,s.jsx)(n.li,{children:"GPU memory management"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Function:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"gpu_execute(filename: str, batchsize: int, megabatch_size: int)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Loads circuit from file (supports gzip compression)"}),"\n",(0,s.jsx)(n.li,{children:"Schedules operations using LUT greedy scheduler"}),"\n",(0,s.jsx)(n.li,{children:"Executes in batches on GPU"}),"\n",(0,s.jsx)(n.li,{children:"Manages GPU memory and timing"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"ray-based-distributed-computing",children:"Ray-Based Distributed Computing"}),"\n",(0,s.jsxs)(n.h4,{id:"worker-pool-ray_workerpy",children:["Worker Pool (",(0,s.jsx)(n.code,{children:"ray_worker.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Distributed worker management for parallel FHE execution."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Classes:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"TFHEWorker"})," - Remote Ray actor for FHE operations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"TFHETqdm"})," - Distributed progress tracking"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"WorkerPool"})," - Manages pool of TFHEWorker instances"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"TFHEWorker Operations:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"and_invert(a, a_ivt, b, b_ivt)"})," - AND with optional input inversion"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"lut2(lut, a, b)"})," - 2-input LUT evaluation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"lut1(lut, a)"})," - 1-input LUT evaluation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"copy_ct(ct)"})," - Ciphertext copying"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"WorkerPool Features:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Automatic load balancing across workers"}),"\n",(0,s.jsx)(n.li,{children:"Progress tracking with tqdm"}),"\n",(0,s.jsx)(n.li,{children:"Configurable worker count"}),"\n",(0,s.jsx)(n.li,{children:"Efficient task distribution"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"circuit-execution-runners",children:"Circuit Execution Runners"}),"\n",(0,s.jsxs)(n.h4,{id:"lut-based-runner-tnfs_lut2_runnerpy",children:["LUT-Based Runner (",(0,s.jsx)(n.code,{children:"tnfs_lut2_runner.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Executes circuits using Look-Up Table (LUT) representation."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Functions:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.code,{children:"tnfs_lut2_runner(schedule, input_state, output, bk, num_workers=8)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Distributed execution using Ray workers"}),"\n",(0,s.jsx)(n.li,{children:"Handles 2-input LUT operations"}),"\n",(0,s.jsx)(n.li,{children:"Manages circuit state throughout execution"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.code,{children:"tnfs_lut2_runner_serial(schedule, input_state, output, bk, num_workers=1)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Serial execution for single-threaded mode"}),"\n",(0,s.jsx)(n.li,{children:"Same functionality as distributed version"}),"\n",(0,s.jsx)(n.li,{children:"Useful for debugging and small circuits"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"tfhe-runners-tfhe_py",children:["TFHE Runners (",(0,s.jsx)(n.code,{children:"tfhe_*.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Various TFHE execution strategies:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"tfhe_serial.py"})})," - Single-threaded TFHE execution"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"tfhe_ray.py"})})," - Ray distributed TFHE execution"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"tfhe_ray_schedule.py"})})," - Advanced Ray scheduling strategies"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"alternative-fhe-backends",children:"Alternative FHE Backends"}),"\n",(0,s.jsxs)(n.h4,{id:"cufhe-integration-cufhe_runnerpy-cufhe_benchmark_driverpy",children:["cuFHE Integration (",(0,s.jsx)(n.code,{children:"cuFHE_runner.py"}),", ",(0,s.jsx)(n.code,{children:"cufhe_benchmark_driver.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Integration with cuFHE library for GPU acceleration."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Supports cuFHE GPU kernels"}),"\n",(0,s.jsx)(n.li,{children:"Benchmark drivers for performance measurement"}),"\n",(0,s.jsx)(n.li,{children:"Alternative to pyTFHEGPU backend"}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"libfhe-support-libfhepy",children:["LibFHE Support (",(0,s.jsx)(n.code,{children:"libfhe.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Generic FHE library integration interface."}),"\n",(0,s.jsx)(n.h3,{id:"benchmarking-and-profiling",children:"Benchmarking and Profiling"}),"\n",(0,s.jsxs)(n.h4,{id:"gpu-benchmarking-gpu_benchmark_driverpy",children:["GPU Benchmarking (",(0,s.jsx)(n.code,{children:"gpu_benchmark_driver.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Performance measurement for GPU execution:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Throughput measurement"}),"\n",(0,s.jsx)(n.li,{children:"Latency profiling"}),"\n",(0,s.jsx)(n.li,{children:"Memory usage tracking"}),"\n",(0,s.jsx)(n.li,{children:"Batch size optimization"}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"sweep-testing-sweeppy",children:["Sweep Testing (",(0,s.jsx)(n.code,{children:"sweep.py"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"Parameter sweep testing for optimization:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Batch size sweeps"}),"\n",(0,s.jsx)(n.li,{children:"Worker count optimization"}),"\n",(0,s.jsx)(n.li,{children:"Performance parameter tuning"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"execution-modes",children:"Execution Modes"}),"\n",(0,s.jsx)(n.h3,{id:"serial-execution",children:"Serial Execution"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Single-threaded execution on CPU"}),"\n",(0,s.jsx)(n.li,{children:"Good for debugging and small circuits"}),"\n",(0,s.jsx)(n.li,{children:"Minimal resource requirements"}),"\n",(0,s.jsxs)(n.li,{children:["Command: ",(0,s.jsx)(n.code,{children:"python -m pyTNFS.runner.main -i circuit.lut -c 1"})]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"ray-distributed-execution",children:"Ray Distributed Execution"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Multi-worker parallel execution on CPU cluster"}),"\n",(0,s.jsx)(n.li,{children:"Scalable across multiple machines"}),"\n",(0,s.jsx)(n.li,{children:"Automatic load balancing"}),"\n",(0,s.jsxs)(n.li,{children:["Command: ",(0,s.jsx)(n.code,{children:"python -m pyTNFS.runner.main -i circuit.lut -c 16 --ray ray://head:10001"})]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"gpu-execution",children:"GPU Execution"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"CUDA-accelerated execution"}),"\n",(0,s.jsx)(n.li,{children:"High throughput for large circuits"}),"\n",(0,s.jsx)(n.li,{children:"Requires NVIDIA GPU with CUDA support"}),"\n",(0,s.jsxs)(n.li,{children:["Command: ",(0,s.jsx)(n.code,{children:"python -m pyTNFS.runner.main_gpu circuit.lut 1024 102400"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"circuit-format-support",children:"Circuit Format Support"}),"\n",(0,s.jsx)(n.h3,{id:"lut-binary-format",children:"LUT Binary Format"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Look-Up Table representation of circuits"}),"\n",(0,s.jsx)(n.li,{children:"Efficient 2-input gate operations"}),"\n",(0,s.jsx)(n.li,{children:"Compressed storage with gzip support"}),"\n",(0,s.jsx)(n.li,{children:"Optimized for parallel execution"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"tnfs-binary-format",children:"TNFS Binary Format"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Threshold Network File System format"}),"\n",(0,s.jsx)(n.li,{children:"Direct circuit representation"}),"\n",(0,s.jsx)(n.li,{children:"Support for various gate types"}),"\n",(0,s.jsx)(n.li,{children:"Compatible with scheduling algorithms"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"batching-strategies",children:"Batching Strategies"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Batch Size"}),": Controls memory vs. parallelism trade-off"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Megabatches"}),": Handle very large circuits by subdividing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Dynamic Batching"}),": Adjust batch sizes based on circuit characteristics"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ray object store for distributed ciphertext sharing"}),"\n",(0,s.jsx)(n.li,{children:"GPU memory allocation and deallocation"}),"\n",(0,s.jsx)(n.li,{children:"Garbage collection integration for large circuits"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"scheduling-integration",children:"Scheduling Integration"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Uses ",(0,s.jsx)(n.code,{children:"tnfs"})," module scheduling algorithms"]}),"\n",(0,s.jsx)(n.li,{children:"Greedy scheduling for LUT-based circuits"}),"\n",(0,s.jsx)(n.li,{children:"Optimization for both serial and parallel execution"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"usage-examples",children:"Usage Examples"}),"\n",(0,s.jsx)(n.h3,{id:"basic-circuit-execution",children:"Basic Circuit Execution"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from pyTNFS.runner.main import *\nimport pyTFHE as t\n\n# Setup FHE parameters\nparams = t.new_default_gate_bootstrapping_parameters(110)\nsk = t.new_random_gate_bootstrapping_secret_keyset(params)\n\n# Load and execute circuit\nwith open("circuit.lut", "rb") as f:\n    binary_data = f.read()\n    \n# Execute with 8 workers\nresults = execute_circuit(binary_data, sk, num_workers=8)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"gpu-execution-1",children:"GPU Execution"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from pyTNFS.runner.main_gpu import gpu_execute\n\n# Execute on GPU with specified batch sizes\ngpu_execute("circuit.lut.gz", batchsize=1024, megabatch_size=102400)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"ray-cluster-setup",children:"Ray Cluster Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import ray\nfrom pyTNFS.runner.tnfs_lut2_runner import tnfs_lut2_runner\n\n# Connect to Ray cluster\nray.init(address="ray://cluster-head:10001")\n\n# Execute distributed\nresults = tnfs_lut2_runner(schedule, inputs, outputs, bk, num_workers=32)\n'})})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}}}]);