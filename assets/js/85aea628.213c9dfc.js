"use strict";(self.webpackChunkpy_tfhe_oss_doc=self.webpackChunkpy_tfhe_oss_doc||[]).push([[5399],{5741:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"chisel-torch/nn","title":"Neural Network Modules","description":"The neural network module package (chiseltorch.nn.module) provides PyTorch-like neural network layers implemented in Chisel for hardware acceleration.","source":"@site/docs/chisel-torch/nn.md","sourceDirName":"chisel-torch","slug":"/chisel-torch/nn","permalink":"/pytfhe/docs/chisel-torch/nn","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chisel-torch/nn.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Hardware Primitives","permalink":"/pytfhe/docs/chisel-torch/hw"}}');var t=l(4848),a=l(8453);const s={sidebar_position:4},i="Neural Network Modules",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Base Module Interface",id:"base-module-interface",level:2},{value:"Core Modules",id:"core-modules",level:2},{value:"Conv2D - 2D Convolution Layer",id:"conv2d---2d-convolution-layer",level:3},{value:"Constructor",id:"constructor",level:4},{value:"Factory Methods",id:"factory-methods",level:4},{value:"Features",id:"features",level:4},{value:"Output Size Calculation",id:"output-size-calculation",level:4},{value:"Example",id:"example",level:4},{value:"Linear - Fully Connected Layer",id:"linear---fully-connected-layer",level:3},{value:"Constructor",id:"constructor-1",level:4},{value:"Factory Method",id:"factory-method",level:4},{value:"Features",id:"features-1",level:4},{value:"Example",id:"example-1",level:4},{value:"ReLU - Rectified Linear Unit",id:"relu---rectified-linear-unit",level:3},{value:"Constructor",id:"constructor-2",level:4},{value:"Factory Method",id:"factory-method-1",level:4},{value:"Features",id:"features-2",level:4},{value:"Example",id:"example-2",level:4},{value:"MaxPool2D - 2D Max Pooling",id:"maxpool2d---2d-max-pooling",level:3},{value:"Constructor",id:"constructor-3",level:4},{value:"Factory Methods",id:"factory-methods-1",level:4},{value:"Features",id:"features-3",level:4},{value:"Output Size Calculation",id:"output-size-calculation-1",level:4},{value:"Example",id:"example-3",level:4},{value:"BatchNorm2d - 2D Batch Normalization",id:"batchnorm2d---2d-batch-normalization",level:3},{value:"Constructor",id:"constructor-4",level:4},{value:"Factory Method",id:"factory-method-2",level:4},{value:"Features",id:"features-4",level:4},{value:"Example",id:"example-4",level:4},{value:"Flatten - Tensor Flattening",id:"flatten---tensor-flattening",level:3},{value:"Constructor",id:"constructor-5",level:4},{value:"Factory Method",id:"factory-method-3",level:4},{value:"Features",id:"features-5",level:4},{value:"Example",id:"example-5",level:4},{value:"Pipe - Pipeline Register",id:"pipe---pipeline-register",level:3},{value:"Constructor",id:"constructor-6",level:4},{value:"Factory Method",id:"factory-method-4",level:4},{value:"Features",id:"features-6",level:4},{value:"Sequential - Neural Network Composition",id:"sequential---neural-network-composition",level:2},{value:"Constructor",id:"constructor-7",level:4},{value:"Features",id:"features-7",level:4},{value:"Example Usage",id:"example-usage",level:4},{value:"Usage Patterns",id:"usage-patterns",level:2},{value:"Creating Individual Modules",id:"creating-individual-modules",level:3},{value:"Building Complete Networks",id:"building-complete-networks",level:3},{value:"Hardware Generation",id:"hardware-generation",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"neural-network-modules",children:"Neural Network Modules"})}),"\n",(0,t.jsxs)(n.p,{children:["The neural network module package (",(0,t.jsx)(n.code,{children:"chiseltorch.nn.module"}),") provides PyTorch-like neural network layers implemented in Chisel for hardware acceleration."]}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsxs)(n.p,{children:["All neural network modules extend the base ",(0,t.jsx)(n.code,{children:"Module"})," trait and implement a common interface for hardware neural networks. The modules support automatic shape inference and parameter management."]}),"\n",(0,t.jsx)(n.h2,{id:"base-module-interface",children:"Base Module Interface"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"trait Module extends chisel3.Module {\n    def input: Data              // Input port\n    def output: Data             // Output port\n    def in_shape: Seq[Int]       // Input tensor shape\n    def out_shape: Seq[Int]      // Output tensor shape  \n    def param_input: Seq[Data]   // Parameter input ports\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"core-modules",children:"Core Modules"}),"\n",(0,t.jsx)(n.h3,{id:"conv2d---2d-convolution-layer",children:"Conv2D - 2D Convolution Layer"}),"\n",(0,t.jsx)(n.p,{children:"Implements 2D convolution with optional padding and configurable stride."}),"\n",(0,t.jsx)(n.h4,{id:"constructor",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class Conv2D(in_channels: Int, out_channels: Int, kernel_size: Int, stride: Int, padding: Int)(in_size: Seq[Int])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"factory-methods",children:"Factory Methods"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"Conv2D(in_channels, out_channels, (kernel_h, kernel_w), stride)(input_shape)           // No padding\nConv2D(in_channels, out_channels, (kernel_h, kernel_w), stride, padding)(input_shape) // With padding\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": 4D tensor (batch=1, channels, height, width)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Weight"}),": 4D tensor (out_channels, in_channels, kernel_height, kernel_width)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": 4D tensor with computed dimensions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hierarchical Design"}),": Uses instantiable modules for efficient hardware generation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Progress Tracking"}),": Shows compilation progress for large convolutions"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"output-size-calculation",children:"Output Size Calculation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"output_height = (input_height + 2*padding - kernel_height) / stride + 1\noutput_width = (input_width + 2*padding - kernel_width) / stride + 1\n"})}),"\n",(0,t.jsx)(n.h4,{id:"example",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val conv = Conv2D(in_channels=3, out_channels=16, (3, 3), stride=1)(Seq(1, 3, 32, 32))\n// Input: (1, 3, 32, 32) -> Output: (1, 16, 30, 30)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"linear---fully-connected-layer",children:"Linear - Fully Connected Layer"}),"\n",(0,t.jsx)(n.p,{children:"Implements matrix multiplication for fully connected neural network layers."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-1",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class Linear(input_dim: Int, output_dim: Int)(input_shape: Seq[Int])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"factory-method",children:"Factory Method"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"Linear(input_dim, output_dim)(input_shape)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-1",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": 2D tensor (batch=1, input_features)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Weight"}),": 2D tensor (input_features, output_features)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": 2D tensor (batch=1, output_features)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hardware"}),": Uses dedicated MatrixMultiplication hardware module"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirements"}),": Input must be exactly 2D"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"example-1",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val linear = Linear(input_dim=784, output_dim=10)(Seq(1, 784))\n// Input: (1, 784) -> Output: (1, 10)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"relu---rectified-linear-unit",children:"ReLU - Rectified Linear Unit"}),"\n",(0,t.jsxs)(n.p,{children:["Implements element-wise ReLU activation function: ",(0,t.jsx)(n.code,{children:"max(0, x)"}),"."]}),"\n",(0,t.jsx)(n.h4,{id:"constructor-2",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class ReLU()(input_shape: Seq[Int])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"factory-method-1",children:"Factory Method"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"ReLU()(input_shape)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-2",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input/Output"}),": Same shape tensor"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Operation"}),": Element-wise ",(0,t.jsx)(n.code,{children:"max(0, x)"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No Parameters"}),": No learnable parameters"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hardware"}),": Uses Mux for conditional logic"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"example-2",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val relu = ReLU()(Seq(1, 16, 28, 28))\n// Input: (1, 16, 28, 28) -> Output: (1, 16, 28, 28)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"maxpool2d---2d-max-pooling",children:"MaxPool2D - 2D Max Pooling"}),"\n",(0,t.jsx)(n.p,{children:"Implements 2D max pooling with configurable kernel size, stride, and padding."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-3",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class MaxPool2D(kernel_size: (Int, Int), stride: Int, padding: Int)(input_shape: Seq[Int])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"factory-methods-1",children:"Factory Methods"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"MaxPool2D((kernel_h, kernel_w), stride)(input_shape)           // No padding\nMaxPool2D((kernel_h, kernel_w), stride, padding)(input_shape) // With padding\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-3",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": 4D tensor (batch=1, channels, height, width)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": 4D tensor with reduced spatial dimensions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Square Kernels"}),": Currently only supports square pooling windows"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hierarchical"}),": Uses per-channel MaxPool2DOne modules"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hardware"}),": Uses dedicated MaxPoolKernel hardware"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"output-size-calculation-1",children:"Output Size Calculation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"output_height = (input_height + 2*padding - kernel_height) / stride + 1\noutput_width = (input_width + 2*padding - kernel_width) / stride + 1\n"})}),"\n",(0,t.jsx)(n.h4,{id:"example-3",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val maxpool = MaxPool2D((2, 2), stride=2)(Seq(1, 16, 28, 28))\n// Input: (1, 16, 28, 28) -> Output: (1, 16, 14, 14)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"batchnorm2d---2d-batch-normalization",children:"BatchNorm2d - 2D Batch Normalization"}),"\n",(0,t.jsx)(n.p,{children:"Implements batch normalization for 2D feature maps."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-4",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class BatchNorm2d(num_features: Int, epsilon: Double)(input_shape: Seq[Int])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"factory-method-2",children:"Factory Method"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"BatchNorm2d(num_features, epsilon)(input_shape)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-4",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": 4D tensor (batch=1, channels, height, width)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Parameters"}),": Mean and variance tensors"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Normalized tensor with same shape"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Formula"}),": ",(0,t.jsx)(n.code,{children:"(x - mean) / (variance + epsilon)"})]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"example-4",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val bn = BatchNorm2d(num_features=16, epsilon=1e-5)(Seq(1, 16, 32, 32))\n// Normalizes each of the 16 channels independently\n"})}),"\n",(0,t.jsx)(n.h3,{id:"flatten---tensor-flattening",children:"Flatten - Tensor Flattening"}),"\n",(0,t.jsx)(n.p,{children:"Reshapes multi-dimensional tensors to 2D for use with Linear layers."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-5",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class Flatten()(input_shape: Seq[Int])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"factory-method-3",children:"Factory Method"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"Flatten()(input_shape)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-5",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": N-dimensional tensor"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": 2D tensor (batch=1, flattened_features)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Operation"}),": Preserves data order, only changes shape"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No Parameters"}),": No learnable parameters"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"example-5",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val flatten = Flatten()(Seq(1, 16, 7, 7))\n// Input: (1, 16, 7, 7) -> Output: (1, 784)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"pipe---pipeline-register",children:"Pipe - Pipeline Register"}),"\n",(0,t.jsx)(n.p,{children:"Adds a register stage for pipelining neural networks."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-6",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class Pipe()(input_shape: Seq[Int])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"factory-method-4",children:"Factory Method"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"Pipe()(input_shape)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-6",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input/Output"}),": Same shape tensor"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Operation"}),": ",(0,t.jsx)(n.code,{children:"RegNext(input)"})," - one clock cycle delay"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Purpose"}),": Pipeline staging for timing closure"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No Parameters"}),": No learnable parameters"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"sequential---neural-network-composition",children:"Sequential - Neural Network Composition"}),"\n",(0,t.jsx)(n.p,{children:"Composes multiple layers into a complete neural network with automatic parameter management."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-7",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class Sequential(layers: Seq[Seq[Int] => Module])(input_shape: Seq[Int])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-7",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Layer Composition"}),": Automatically connects layer outputs to inputs"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Shape Inference"}),": Automatically computes shapes between layers"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Parameter Management"}),": Creates IO ports for each layer's parameters"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Logging"}),": Prints layer information during elaboration"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"example-usage",children:"Example Usage"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val network = new Sequential(\n    Seq(\n        Conv2D(3, 16, (3, 3), 1),     // 3->16 channels, 3x3 kernel\n        ReLU(),                        // Activation\n        MaxPool2D((2, 2), 2),         // 2x2 pooling, stride 2\n        Flatten(),                     // Reshape for linear\n        Linear(784, 10),              // Fully connected\n        ReLU()                        // Final activation\n    )\n)(Seq(1, 3, 32, 32))                  // Input: 32x32 RGB images\n"})}),"\n",(0,t.jsx)(n.h2,{id:"usage-patterns",children:"Usage Patterns"}),"\n",(0,t.jsx)(n.h3,{id:"creating-individual-modules",children:"Creating Individual Modules"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"// Convolution with automatic shape inference\nval conv = Conv2D(in_channels=3, out_channels=64, (5, 5), stride=1, padding=2)(input_shape)\n\n// Connect inputs and parameters\nconv.input := input_tensor.toVec\nconv.param_input.head := weight_tensor.toVec\noutput_tensor := conv.output\n"})}),"\n",(0,t.jsx)(n.h3,{id:"building-complete-networks",children:"Building Complete Networks"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"// Define layer sequence\nval layers = Seq(\n    Pipe(),                           // Input pipeline stage\n    Conv2D(3, 32, (3, 3), 1),        // First convolution\n    ReLU(),                           // Activation\n    Pipe(),                           // Pipeline stage\n    MaxPool2D((2, 2), 2),            // Pooling\n    Flatten(),                        // Reshape\n    Linear(8192, 1000),              // Classification layer\n    ReLU()                            // Output activation\n)\n\nval network = new Sequential(layers)(Seq(1, 3, 224, 224))\n"})}),"\n",(0,t.jsx)(n.h3,{id:"hardware-generation",children:"Hardware Generation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"// Generate Verilog for individual modules\n(new ChiselStage).emitVerilog(new Conv2D(3, 16, 3, 1, 0)(Seq(1, 3, 32, 32)))\n\n// Generate FIRRTL for complete networks\n(new ChiselStage).emitChirrtl(network)\n"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,l)=>{l.d(n,{R:()=>s,x:()=>i});var r=l(6540);const t={},a=r.createContext(t);function s(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);