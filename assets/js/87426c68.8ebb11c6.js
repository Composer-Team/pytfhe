"use strict";(self.webpackChunkpy_tfhe_oss_doc=self.webpackChunkpy_tfhe_oss_doc||[]).push([[7977],{824:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"chisel-torch/tensors","title":"Tensor Module","description":"The tensor module (chiseltorch.tensor) provides the core tensor abstraction for ChiselTorch, implementing hardware-aware multi-dimensional arrays with PyTorch-like operations.","source":"@site/docs/chisel-torch/tensors.md","sourceDirName":"chisel-torch","slug":"/chisel-torch/tensors","permalink":"/pytfhe/docs/chisel-torch/tensors","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chisel-torch/tensors.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"ChiselTorch Overview","permalink":"/pytfhe/docs/chisel-torch/overview"},"next":{"title":"Hardware Primitives","permalink":"/pytfhe/docs/chisel-torch/hw"}}');var r=s(4848),o=s(8453);const a={sidebar_position:2},t="Tensor Module",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Tensor Class",id:"tensor-class",level:2},{value:"Constructor",id:"constructor",level:3},{value:"Key Properties",id:"key-properties",level:3},{value:"Indexing Operations",id:"indexing-operations",level:3},{value:"Single Index Access",id:"single-index-access",level:4},{value:"Multi-Index Access",id:"multi-index-access",level:4},{value:"Dimension Selection",id:"dimension-selection",level:4},{value:"Functional Operations",id:"functional-operations",level:3},{value:"Map Operation",id:"map-operation",level:4},{value:"Element-wise Addition",id:"element-wise-addition",level:4},{value:"Hardware Interface",id:"hardware-interface",level:3},{value:"Chisel Vec Conversion",id:"chisel-vec-conversion",level:4},{value:"Assignment Operations",id:"assignment-operations",level:4},{value:"Reshape",id:"reshape",level:4},{value:"Tensor Object (Factory Methods)",id:"tensor-object-factory-methods",level:2},{value:"Construction Methods",id:"construction-methods",level:3},{value:"Hardware Constructors",id:"hardware-constructors",level:3},{value:"Tensor Operations (Ops Object)",id:"tensor-operations-ops-object",level:2},{value:"Reduction Operations",id:"reduction-operations",level:3},{value:"Activation Functions",id:"activation-functions",level:3},{value:"Linear Algebra",id:"linear-algebra",level:3},{value:"Convolution Operations",id:"convolution-operations",level:3},{value:"Pooling Operations",id:"pooling-operations",level:3},{value:"Normalization",id:"normalization",level:3},{value:"Tensor Concatenation",id:"tensor-concatenation",level:3},{value:"Usage Examples",id:"usage-examples",level:2},{value:"Creating Tensors",id:"creating-tensors",level:3},{value:"Matrix Operations",id:"matrix-operations",level:3},{value:"Convolution Example",id:"convolution-example",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"tensor-module",children:"Tensor Module"})}),"\n",(0,r.jsxs)(n.p,{children:["The tensor module (",(0,r.jsx)(n.code,{children:"chiseltorch.tensor"}),") provides the core tensor abstraction for ChiselTorch, implementing hardware-aware multi-dimensional arrays with PyTorch-like operations."]}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"The tensor module consists of two main components:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tensor class"}),": The main tensor data structure for storing and manipulating multi-dimensional data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ops object"}),": Collection of tensor operations (convolutions, matrix multiplication, etc.)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"tensor-class",children:"Tensor Class"}),"\n",(0,r.jsx)(n.h3,{id:"constructor",children:"Constructor"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"class Tensor[T <: DType[T]](val shape: Seq[Int], val data: Seq[T])\n"})}),"\n",(0,r.jsxs)(n.p,{children:["A generic tensor parameterized by data type ",(0,r.jsx)(n.code,{children:"T"})," that extends ",(0,r.jsx)(n.code,{children:"DType[T]"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"key-properties",children:"Key Properties"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"shape"}),": ",(0,r.jsx)(n.code,{children:"Seq[Int]"})," - Dimensions of the tensor"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"data"}),": ",(0,r.jsx)(n.code,{children:"Seq[T]"})," - Flattened data elements stored in row-major order"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"indexing-operations",children:"Indexing Operations"}),"\n",(0,r.jsx)(n.h4,{id:"single-index-access",children:"Single Index Access"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def apply(index: Int): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Returns a tensor with one less dimension by selecting along the first axis."}),"\n",(0,r.jsx)(n.h4,{id:"multi-index-access",children:"Multi-Index Access"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def apply(index: Int*): Tensor[T]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Supports multi-dimensional indexing like ",(0,r.jsx)(n.code,{children:"tensor(i, j, k)"}),"."]}),"\n",(0,r.jsx)(n.h4,{id:"dimension-selection",children:"Dimension Selection"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def indexDim(dim: Int, sel: Int): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Selects a specific index along a given dimension."}),"\n",(0,r.jsx)(n.h3,{id:"functional-operations",children:"Functional Operations"}),"\n",(0,r.jsx)(n.h4,{id:"map-operation",children:"Map Operation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def map[U <: DType[U]](f: T => U): Tensor[U]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Applies a function to each element, potentially changing the data type."}),"\n",(0,r.jsx)(n.h4,{id:"element-wise-addition",children:"Element-wise Addition"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def +(that: Tensor[T]): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Element-wise addition of two tensors."}),"\n",(0,r.jsx)(n.h3,{id:"hardware-interface",children:"Hardware Interface"}),"\n",(0,r.jsx)(n.h4,{id:"chisel-vec-conversion",children:"Chisel Vec Conversion"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def toVec: chisel3.Vec[T]        // Convert to Chisel Vec\ndef asVecType: chisel3.Vec[T]    // Get Vec type for IO\n"})}),"\n",(0,r.jsx)(n.h4,{id:"assignment-operations",children:"Assignment Operations"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def :=(that: chisel3.Vec[T]): Unit      // Assign from Vec\ndef :=(that: Tensor[T]): Unit           // Assign from Tensor  \ndef :=(that: T): Unit                   // Broadcast assignment\ndef :=(that: chisel3.UInt): Unit        // Assign from UInt\n"})}),"\n",(0,r.jsx)(n.h4,{id:"reshape",children:"Reshape"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def reshape(new_shape: Seq[Int]): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Changes tensor shape while preserving total number of elements."}),"\n",(0,r.jsx)(n.h2,{id:"tensor-object-factory-methods",children:"Tensor Object (Factory Methods)"}),"\n",(0,r.jsx)(n.h3,{id:"construction-methods",children:"Construction Methods"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def apply[T <: DType[T]](shape: Seq[Int], data: Seq[T]): Tensor[T]\ndef empty[T <: DType[T]](shape: Seq[Int], dtype_constructor: () => T): Tensor[T]\ndef zeros[T <: DType[T]](shape: Seq[Int], dtype_constructor: () => T): Tensor[T]\ndef Lit[T <: DType[T]](shape: Seq[Int], data: Seq[Float], dtype_constructor: () => T): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.h3,{id:"hardware-constructors",children:"Hardware Constructors"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def Wire[T <: DType[T]](tensor: Tensor[T]): Tensor[T]    // Wire version\ndef Reg[T <: DType[T]](tensor: Tensor[T]): Tensor[T]     // Register version\n"})}),"\n",(0,r.jsx)(n.h2,{id:"tensor-operations-ops-object",children:"Tensor Operations (Ops Object)"}),"\n",(0,r.jsx)(n.h3,{id:"reduction-operations",children:"Reduction Operations"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def sum[T <: DType[T]](a: Tensor[T]): T                  // Sum all elements\ndef max[T <: DType[T]](a: Tensor[T]): T                  // Max element\n"})}),"\n",(0,r.jsx)(n.h3,{id:"activation-functions",children:"Activation Functions"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def relu[T <: DType[T]](a: Tensor[T]): Tensor[T]         // ReLU activation\n"})}),"\n",(0,r.jsx)(n.h3,{id:"linear-algebra",children:"Linear Algebra"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def mm[T <: DType[T]](a: Tensor[T], b: Tensor[T]): Tensor[T]      // Matrix multiplication\ndef matmul[T <: DType[T]](a: Tensor[T], b: Tensor[T]): Tensor[T]  // Alias for mm\n"})}),"\n",(0,r.jsx)(n.h3,{id:"convolution-operations",children:"Convolution Operations"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def conv2d[T <: DType[T]](input: Tensor[T], weight: Tensor[T], stride: Int): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.p,{children:"2D convolution with configurable stride. Expects:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"input"}),": 4D tensor (batch, channels, height, width)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"weight"}),": 4D tensor (out_channels, in_channels, kernel_height, kernel_width)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"stride"}),": Step size for convolution"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def zero_padding[T <: DType[T]](in_tensor: Tensor[T], padding: Int): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Adds zero padding around tensor borders."}),"\n",(0,r.jsx)(n.h3,{id:"pooling-operations",children:"Pooling Operations"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def max_pool2d[T <: DType[T]](input: Tensor[T], kernel_size: (Int, Int), stride: Option[Int]): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.p,{children:"2D max pooling with configurable kernel size and stride."}),"\n",(0,r.jsx)(n.h3,{id:"normalization",children:"Normalization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def batch_norm[T <: DType[T]](input: Tensor[T], mean: T, variance: T, epsilon: T): Tensor[T]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Batch normalization: ",(0,r.jsx)(n.code,{children:"(x - mean) / (variance + epsilon)"})]}),"\n",(0,r.jsx)(n.h3,{id:"tensor-concatenation",children:"Tensor Concatenation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"def concat[T <: DType[T]](inputs: Seq[Tensor[T]], dim: Int): Tensor[T]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Concatenates tensors along specified dimension (currently only supports channel dimension)."}),"\n",(0,r.jsx)(n.h2,{id:"usage-examples",children:"Usage Examples"}),"\n",(0,r.jsx)(n.h3,{id:"creating-tensors",children:"Creating Tensors"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"// Create empty tensor\nval tensor = Tensor.empty(Seq(2, 3, 4), () => chiseltorch.dtypes.UInt(8.W))\n\n// Create wire version for hardware\nval wire_tensor = Tensor.Wire(tensor)\n\n// Create zero tensor\nval zeros = Tensor.zeros(Seq(10, 10), () => chiseltorch.dtypes.Float())\n"})}),"\n",(0,r.jsx)(n.h3,{id:"matrix-operations",children:"Matrix Operations"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"val a = Tensor(Seq(2, 3), data_a)\nval b = Tensor(Seq(3, 4), data_b)\nval result = Ops.mm(a, b)  // 2x4 result\n"})}),"\n",(0,r.jsx)(n.h3,{id:"convolution-example",children:"Convolution Example"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-scala",children:"val input = Tensor.empty(Seq(1, 3, 32, 32), () => UInt(8.W))    // Batch=1, RGB, 32x32\nval weight = Tensor.empty(Seq(16, 3, 3, 3), () => UInt(8.W))    // 16 filters, 3x3 kernels\nval output = Ops.conv2d(input, weight, stride = 1)              // Result: (1, 16, 30, 30)\n"})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>t});var i=s(6540);const r={},o=i.createContext(r);function a(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);