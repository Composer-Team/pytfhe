"use strict";(self.webpackChunkpy_tfhe_oss_doc=self.webpackChunkpy_tfhe_oss_doc||[]).push([[5489],{6841:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>s,default:()=>p,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"chisel-torch/hw","title":"Hardware Primitives","description":"The hardware operations package (chiseltorch.hw) provides optimized hardware implementations of fundamental operations used by higher-level neural network modules.","source":"@site/docs/chisel-torch/hw.md","sourceDirName":"chisel-torch","slug":"/chisel-torch/hw","permalink":"/pytfhe/docs/chisel-torch/hw","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chisel-torch/hw.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Tensor Module","permalink":"/pytfhe/docs/chisel-torch/tensors"},"next":{"title":"Neural Network Modules","permalink":"/pytfhe/docs/chisel-torch/nn"}}');var t=r(4848),a=r(8453);const l={sidebar_position:3},s="Hardware Primitives",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Matrix Operations",id:"matrix-operations",level:2},{value:"DotProduct - Vector Dot Product",id:"dotproduct---vector-dot-product",level:3},{value:"Constructor",id:"constructor",level:4},{value:"Features",id:"features",level:4},{value:"Hardware Implementation",id:"hardware-implementation",level:4},{value:"IO Interface",id:"io-interface",level:4},{value:"MatrixMultiplication - 2D Matrix Multiply",id:"matrixmultiplication---2d-matrix-multiply",level:3},{value:"Constructor",id:"constructor-1",level:4},{value:"Parameters",id:"parameters",level:4},{value:"Features",id:"features-1",level:4},{value:"Hardware Architecture",id:"hardware-architecture",level:4},{value:"Usage Example",id:"usage-example",level:4},{value:"Pooling Operations",id:"pooling-operations",level:2},{value:"MaxPoolKernel - Pooling Window",id:"maxpoolkernel---pooling-window",level:3},{value:"Constructor",id:"constructor-2",level:4},{value:"Features",id:"features-2",level:4},{value:"IO Interface",id:"io-interface-1",level:4},{value:"Usage in Higher-Level Modules",id:"usage-in-higher-level-modules",level:4},{value:"Vector Operations",id:"vector-operations",level:2},{value:"VectorOpSingle - Unary Vector Operations",id:"vectoropsingle---unary-vector-operations",level:3},{value:"Constructor",id:"constructor-3",level:4},{value:"Features",id:"features-3",level:4},{value:"Example Operations",id:"example-operations",level:4},{value:"VectorOpDouble - Binary Vector Operations",id:"vectoropdouble---binary-vector-operations",level:3},{value:"Constructor",id:"constructor-4",level:4},{value:"Features",id:"features-4",level:4},{value:"Hardware Implementation",id:"hardware-implementation-1",level:4},{value:"IO Interface",id:"io-interface-2",level:4},{value:"Example Operations",id:"example-operations-1",level:4},{value:"Design Patterns",id:"design-patterns",level:2},{value:"Instantiable Modules",id:"instantiable-modules",level:3},{value:"Progress Tracking",id:"progress-tracking",level:3},{value:"Type Safety",id:"type-safety",level:3},{value:"Hardware Generation",id:"hardware-generation",level:2},{value:"Individual Modules",id:"individual-modules",level:3},{value:"Integration Examples",id:"integration-examples",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"hardware-primitives",children:"Hardware Primitives"})}),"\n",(0,t.jsxs)(n.p,{children:["The hardware operations package (",(0,t.jsx)(n.code,{children:"chiseltorch.hw"}),") provides optimized hardware implementations of fundamental operations used by higher-level neural network modules."]}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"Hardware operations are designed as reusable, instantiable modules that can be efficiently composed into larger neural network architectures. They focus on performance-critical operations like matrix multiplication, pooling, and vector operations."}),"\n",(0,t.jsx)(n.h2,{id:"matrix-operations",children:"Matrix Operations"}),"\n",(0,t.jsx)(n.h3,{id:"dotproduct---vector-dot-product",children:"DotProduct - Vector Dot Product"}),"\n",(0,t.jsx)(n.p,{children:"Computes the dot product (inner product) of two equal-length vectors."}),"\n",(0,t.jsx)(n.h4,{id:"constructor",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class DotProduct[T <: DType[T]](length: Int, in_dtype_constructor: () => T)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Generic Type"}),": Supports any ",(0,t.jsx)(n.code,{children:"DType[T]"})," data type"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": Two vectors of length ",(0,t.jsx)(n.code,{children:"length"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Single scalar value (sum of element-wise products)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Operation"}),": ",(0,t.jsx)(n.code,{children:"\u2211(a[i] * b[i])"})," for i = 0 to length-1"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Instantiable"}),": Marked with ",(0,t.jsx)(n.code,{children:"@instantiable"})," for hierarchical reuse"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"hardware-implementation",children:"Hardware Implementation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val output_data = tensor_a.data.zip(tensor_b.data).map { case (a, b) => a * b }.reduce(_ + _)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"io-interface",children:"IO Interface"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val io = IO(new Bundle {\n    val a = Input(tensor_a.asVecType)    // First vector input\n    val b = Input(tensor_b.asVecType)    // Second vector input  \n    val c = Output(output_tensor.asVecType) // Scalar result\n})\n"})}),"\n",(0,t.jsx)(n.h3,{id:"matrixmultiplication---2d-matrix-multiply",children:"MatrixMultiplication - 2D Matrix Multiply"}),"\n",(0,t.jsx)(n.p,{children:"Implements general matrix multiplication using a grid of dot product units."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-1",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class MatrixMultiplication[T <: DType[T]](shape_a: Seq[Int], shape_b: Seq[Int], dtype_constructor: () => T)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"parameters",children:"Parameters"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"shape_a"}),": ",(0,t.jsx)(n.code,{children:"Seq(M, K)"})," - Dimensions of first matrix"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"shape_b"}),": ",(0,t.jsx)(n.code,{children:"Seq(K, N)"})," - Dimensions of second matrix"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": ",(0,t.jsx)(n.code,{children:"Seq(M, N)"})," - Result matrix dimensions"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"features-1",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Shape Validation"}),": Ensures inner dimensions match (",(0,t.jsx)(n.code,{children:"K"})," must be equal)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hierarchical Design"}),": Creates ",(0,t.jsx)(n.code,{children:"M \xd7 N"})," DotProduct instances"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Progress Tracking"}),": Shows compilation progress for large matrices"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Generic Types"}),": Supports any ",(0,t.jsx)(n.code,{children:"DType[T]"})," data type"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"hardware-architecture",children:"Hardware Architecture"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"// Creates M\xd7N dot product units in a grid\nfor (i <- 0 until shape_a(0)) {        // M rows\n    for (j <- 0 until shape_b(1)) {    // N columns\n        val dot_prod = Instance(ref_dot_prod)\n        dot_prod.io.a := tensor_a(i).toVec           // Row i of A\n        dot_prod.io.b := tensor_b.indexDim(1, j).toVec  // Column j of B\n        tensor_c(i, j) := dot_prod.io.c              // Result element\n    }\n}\n"})}),"\n",(0,t.jsx)(n.h4,{id:"usage-example",children:"Usage Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val matmul = Module(new MatrixMultiplication(Seq(64, 128), Seq(128, 32), () => UInt(8.W)))\n// Multiplies 64\xd7128 matrix with 128\xd732 matrix to get 64\xd732 result\n"})}),"\n",(0,t.jsx)(n.h2,{id:"pooling-operations",children:"Pooling Operations"}),"\n",(0,t.jsx)(n.h3,{id:"maxpoolkernel---pooling-window",children:"MaxPoolKernel - Pooling Window"}),"\n",(0,t.jsx)(n.p,{children:"Finds the maximum value within a pooling window."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-2",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class MaxPoolKernel[T <: DType[T]](kernel_size: (Int, Int), dtype_constructor: () => T)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-2",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": Flattened pooling window (",(0,t.jsx)(n.code,{children:"kernel_height \xd7 kernel_width"})," elements)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Single maximum value"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Generic Type"}),": Works with any comparable ",(0,t.jsx)(n.code,{children:"DType[T]"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Operation"}),": Uses ",(0,t.jsx)(n.code,{children:"Ops.max()"})," to find maximum element"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"io-interface-1",children:"IO Interface"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val io = IO(new Bundle {\n    val in = Input(input_tensor.asVecType)   // Flattened window\n    val out = Output(output.cloneType)       // Maximum value\n})\n"})}),"\n",(0,t.jsx)(n.h4,{id:"usage-in-higher-level-modules",children:"Usage in Higher-Level Modules"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val maxpool_kernel = Instance(maxpool_kernel_ref)\nmaxpool_kernel.io.in := VecInit(pooling_window)\nval max_value = maxpool_kernel.io.out\n"})}),"\n",(0,t.jsx)(n.h2,{id:"vector-operations",children:"Vector Operations"}),"\n",(0,t.jsx)(n.h3,{id:"vectoropsingle---unary-vector-operations",children:"VectorOpSingle - Unary Vector Operations"}),"\n",(0,t.jsx)(n.p,{children:"Applies a unary function element-wise to a tensor."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-3",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class VectorOpSingle[T <: DType[T], U <: DType[U]](shape: Seq[Int], op: T => U, in_dtype_constructor: () => T)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-3",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Generic Types"}),": Input type ",(0,t.jsx)(n.code,{children:"T"})," and output type ",(0,t.jsx)(n.code,{children:"U"})," can differ"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Functional"}),": Takes a function ",(0,t.jsx)(n.code,{children:"T => U"})," as parameter"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Element-wise"}),": Applies operation to each tensor element independently"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Shape Preserving"}),": Output has same shape as input"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"example-operations",children:"Example Operations"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"// ReLU operation\nval relu_op = (x: UInt) => Mux(x > 0.U, x, 0.U)\nval relu_vector = new VectorOpSingle(shape, relu_op, () => UInt(8.W))\n\n// Type conversion\nval float_convert = (x: UInt) => x.asTypeOf(Float())\nval converter = new VectorOpSingle(shape, float_convert, () => UInt(8.W))\n"})}),"\n",(0,t.jsx)(n.h3,{id:"vectoropdouble---binary-vector-operations",children:"VectorOpDouble - Binary Vector Operations"}),"\n",(0,t.jsx)(n.p,{children:"Applies a binary function element-wise to pairs of tensor elements."}),"\n",(0,t.jsx)(n.h4,{id:"constructor-4",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class VectorOpDouble[T <: DType[T], U <: DType[U]](shape: Seq[Int], op: (T, T) => U, in_dtype_constructor: () => T)\n"})}),"\n",(0,t.jsx)(n.h4,{id:"features-4",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Two Inputs"}),": Takes two tensors of identical shape"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Element-wise"}),": Applies ",(0,t.jsx)(n.code,{children:"op(a[i], b[i])"})," to corresponding elements"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Generic Output"}),": Output type ",(0,t.jsx)(n.code,{children:"U"})," can differ from input type ",(0,t.jsx)(n.code,{children:"T"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Functional"}),": Operation specified as ",(0,t.jsx)(n.code,{children:"(T, T) => U"})," function"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"hardware-implementation-1",children:"Hardware Implementation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val output_data = tensor_a.data.zip(tensor_b.data).map { case (a, b) => op(a, b) }\n"})}),"\n",(0,t.jsx)(n.h4,{id:"io-interface-2",children:"IO Interface"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val io = IO(new Bundle {\n    val a = Input(tensor_a.asVecType)      // First operand\n    val b = Input(tensor_b.asVecType)      // Second operand\n    val c = Output(output_tensor.asVecType) // Result\n})\n"})}),"\n",(0,t.jsx)(n.h4,{id:"example-operations-1",children:"Example Operations"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"// Element-wise addition\nval add_op = (x: UInt, y: UInt) => x + y\nval adder = new VectorOpDouble(shape, add_op, () => UInt(8.W))\n\n// Element-wise multiplication  \nval mul_op = (x: UInt, y: UInt) => x * y\nval multiplier = new VectorOpDouble(shape, mul_op, () => UInt(8.W))\n\n// Comparison\nval gt_op = (x: UInt, y: UInt) => Mux(x > y, 1.U, 0.U)\nval comparator = new VectorOpDouble(shape, gt_op, () => UInt(8.W))\n"})}),"\n",(0,t.jsx)(n.h2,{id:"design-patterns",children:"Design Patterns"}),"\n",(0,t.jsx)(n.h3,{id:"instantiable-modules",children:"Instantiable Modules"}),"\n",(0,t.jsxs)(n.p,{children:["All hardware operations use the ",(0,t.jsx)(n.code,{children:"@instantiable"})," annotation for efficient hierarchical design:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"@instantiable\nclass MyHardwareOp extends Module {\n    @public val io = IO(new Bundle { ... })\n    // Implementation\n}\n\n// Usage in higher-level modules\nval ref = Definition(new MyHardwareOp(...))\nval instance = Instance(ref)  // Reuses the same definition\n"})}),"\n",(0,t.jsx)(n.h3,{id:"progress-tracking",children:"Progress Tracking"}),"\n",(0,t.jsx)(n.p,{children:"Large operations provide progress feedback during compilation:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val pbar = new ProgressBar(total_operations)\nfor (i <- 0 until total_operations) {\n    // Do work\n    pbar.update(1)\n}\npbar.finished()\n"})}),"\n",(0,t.jsx)(n.h3,{id:"type-safety",children:"Type Safety"}),"\n",(0,t.jsxs)(n.p,{children:["All operations are parameterized by ",(0,t.jsx)(n.code,{children:"DType[T]"})," for type safety:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class MyOp[T <: DType[T]](dtype_constructor: () => T) extends Module {\n    val data = Tensor.empty(shape, dtype_constructor)  // Type-safe tensor creation\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"hardware-generation",children:"Hardware Generation"}),"\n",(0,t.jsx)(n.h3,{id:"individual-modules",children:"Individual Modules"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"// Generate Verilog for matrix multiplication\n(new ChiselStage).emitVerilog(\n    new MatrixMultiplication(Seq(32, 64), Seq(64, 16), () => UInt(8.W))\n)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"integration-examples",children:"Integration Examples"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"// Use in neural network layer\nval matmul_hw = Module(new MatrixMultiplication(input_shape, weight_shape, dtype_constructor))\nmatmul_hw.io.a := input_tensor.toVec\nmatmul_hw.io.b := weight_tensor.toVec\noutput_tensor := matmul_hw.io.c\n"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>s});var i=r(6540);const t={},a=i.createContext(t);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);